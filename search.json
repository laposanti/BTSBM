[{"path":"https://laposanti.github.io/BTSBM/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Lapo Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Post-processing and Summary Plots for BT-SBM","text":"vignette shows typical post-processing pipeline Bayesian Bradley–Terry Stochastic Block Models (BT-SBM): - relabel posterior draws, - compute player-level skill summaries, - summarize uncertainty (entropy, cluster counts), - generate publication-ready plots. uses package dataset ATP_2000_2022 head--head panels. Posterior draws come separate MCMC run (saved .rds file).","code":""},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"dependencies","dir":"Articles","previous_headings":"Overview","what":"Dependencies","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"library(BTSBM)         library(ggplot2) library(dplyr) library(tidyr) library(coda) library(mcclust) library(mcclust.ext) library(ggrepel) library(kableExtra) library(reshape2) library(stringr) library(ggside)"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"data","dir":"Articles","previous_headings":"Overview","what":"Data","title":"Post-processing and Summary Plots for BT-SBM","text":"yearly element contains: Y_ij, pairwise victory matrix N_ij, pairwise matches count matrix (105×105), players_df (105×7: player, worst_rank, median_rank, last_rank, age_year, ht_year, player_slug). use structure align player indices posterior draws.","code":"data(ATP_2000_2022, package = \"BTSBM\") names(ATP_2000_2022)[1:3] year_idx <- 1 str(ATP_2000_2022[[year_idx]], max.level = 1) f <- system.file(\"extdata\", \"resGN_demo.rds\", package = \"BTSBM\") res_list <- readRDS(f)  first_year <- 1999"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"cross-season-summaries","dir":"Articles","previous_headings":"Overview","what":"Cross-season summaries","title":"Post-processing and Summary Plots for BT-SBM","text":"iterate seasons, relabel draws, compute entropy skill summaries, collect posterior number blocks.","code":"top_block_counts_across_years <- tibble(season = character(), avg_top_block_cnt = numeric()) prob_assignment_across_years  <- tibble() post_numb_block_across_years  <- tibble(season = character(), num_blocks = integer(), count = integer(), prob = numeric()) avg_strength_each_player      <- tibble() entropy_per_season            <- tibble(season = character(), quantile005 = numeric(),                                         quantile095 = numeric(), mean_entropy = numeric())  for (yr in seq_along(res_list)) {   season_label <- paste0(first_year + yr, \"/\", first_year + yr + 1)   res_i <- res_list[[yr]]   x_samples <- res_i$x_samples   lambda_samples <- res_i$lambda_samples    inf_i <- inference_helper(x_samples, lambda_samples)   x_relabeled <- inf_i$x_samples_relabel   lambdas_reordered <- inf_i$lambda_samples_relabel   T_iter <- nrow(lambdas_reordered)   n_players <- ncol(lambdas_reordered)    # player-level λ (geometric mean normalization by unique λ's per draw)   pl_lambda <- matrix(0, nrow = T_iter, ncol = n_players)   entropy_container <- numeric(T_iter)    for (i in 1:T_iter) {     x_cur <- x_relabeled[i, ]     p1 <- mean(x_cur == 1); p2 <- 1 - p1     entropy_container[i] <- -sum(c(p1, p2) * log(c(p1, p2) + 1e-10))      lambda_cur <- lambdas_reordered[i, ]     unique_lambdas <- unique(lambda_cur)     new_unique_lambdas <- unique_lambdas / (prod(unique_lambdas)^(1 / length(unique_lambdas)))     pl_lambda[i, ] <- new_unique_lambdas[x_cur]   }    HPD_entropy <- HPDinterval(as.mcmc(entropy_container))   entropy_per_season <- bind_rows(entropy_per_season, tibble(     season = season_label,     quantile005 = HPD_entropy[1],     quantile095 = HPD_entropy[2],     mean_entropy = mean(entropy_container)   ))    avg_strength_each_player <- bind_rows(avg_strength_each_player, tibble(     season = rep(season_label, n_players),     mean_str = apply(pl_lambda, 2, median, na.rm = TRUE),     lower_quantile = apply(pl_lambda, 2, quantile, probs = 0.025),     upper_quantile = apply(pl_lambda, 2, quantile, probs = 0.975)   ))    top_block_counts_across_years <- bind_rows(top_block_counts_across_years, tibble(     season = season_label, avg_top_block_cnt = inf_i$avg_top_block_count   ))    # align with package data   tennis_years <- ATP_2000_2022   block_assignment_i <- inf_i$player_block_assignment_probs   block_assignment_i$season <- season_label   block_assignment_i$pl_name <- rownames(tennis_years[[yr]]$Y_ij)   block_assignment_i$eos_ranking <- tennis_years[[yr]]$players_df$last_rank   block_assignment_i$pl_name <- gsub(\"_\", \" \", block_assignment_i$pl_name)   prob_assignment_across_years <- bind_rows(prob_assignment_across_years, block_assignment_i)    post_numb_blocks_i <- inf_i$block_count_distribution   post_numb_blocks_i$season <- season_label   post_numb_block_across_years <- bind_rows(post_numb_block_across_years, post_numb_blocks_i) }"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"posterior-for-the-number-of-blocks-table","dir":"Articles","previous_headings":"Overview > Cross-season summaries","what":"Posterior for the number of blocks (table)","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"post_numb_block_across_years_wide <- post_numb_block_across_years %>%   filter(num_blocks < 7) %>%   select(-count) %>%   pivot_wider(names_from = num_blocks, values_from = prob)  num_blocks_season <- post_numb_block_across_years %>%   group_by(season) %>%   summarise(num_blocks = num_blocks[which.max(prob)], .groups = \"drop\") %>%   mutate(num_blocks = factor(num_blocks, ordered = TRUE))  kable(post_numb_block_across_years_wide, format = \"html\", digits = 3) %>%   kable_styling(full_width = FALSE)"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"jitter-plot-probability-of-top-block-membership","dir":"Articles","previous_headings":"Overview > Cross-season summaries","what":"Jitter plot: probability of top-block membership","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"prob_assignment_across_years <- prob_assignment_across_years %>%   left_join(num_blocks_season, by = \"season\")  prob_assignment_across_years$season <- factor(   prob_assignment_across_years$season,   levels = unique(prob_assignment_across_years$season) )  ggplot(prob_assignment_across_years, aes(x = season, y = Cluster_1)) +   geom_jitter(aes(color = factor(num_blocks)), width = 0.2, alpha = 0.6, size = 2.8) +   labs(x = \"Season\", y = \"P(Top Block)\", color = \"Nº blocks\") +   theme_minimal() +   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),         panel.grid.minor = element_blank())"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"entropy-over-time","dir":"Articles","previous_headings":"Overview > Cross-season summaries","what":"Entropy over time","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"entropy_per_season %>%   mutate(season_start = as.numeric(sub(\"/.*\", \"\", season))) %>%   ggplot(aes(x = season_start, y = mean_entropy)) +   geom_ribbon(aes(ymin = quantile005, ymax = quantile095), alpha = 0.4) +   geom_line(size = 1.2) +   geom_point(size = 2.5) +   scale_x_continuous(breaks = unique(as.numeric(sub(\"/.*\", \"\", entropy_per_season$season)))) +   theme_minimal(base_size = 12) +   labs(x = \"Season\", y = \"Shannon Entropy\")"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"count-of-top-block-members-by-season","dir":"Articles","previous_headings":"Overview > Cross-season summaries","what":"Count of top-block members by season","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"num_block_plot <- prob_assignment_across_years %>%   pivot_longer(cols = -c(season, pl_name, num_blocks, eos_ranking),                names_to = \"cluster\", values_to = \"prob\") %>%   group_by(season, pl_name) %>%   reframe(ass_cluster = cluster[which.max(prob)]) %>%   ungroup() %>%   group_by(season) %>%   count(ass_cluster) %>%   filter(ass_cluster == \"Cluster_1\") %>%   left_join(num_blocks_season, by = \"season\") %>%   ggplot(aes(x = season, y = n, fill = num_blocks)) +   geom_col() +   theme_minimal() +   labs(x = \"Season\", y = \"Nº of Players in Top Block\", fill = \"Nº blocks\") +   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),         panel.grid.minor = element_blank()) num_block_plot"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"focused-analysis-for-a-single-season","dir":"Articles","previous_headings":"Overview","what":"Focused analysis for a single season","title":"Post-processing and Summary Plots for BT-SBM","text":"show relabel decreasing λ\\lambda, plot λ\\lambda uncertainty, build block-ordered adjacency heatmaps, visualize assignment probabilities. Replace yr desired index ensure .rds file available.","code":"first_year <- 1999 yr <- 18                # example: -> \"2017/2018\" model <- \"GN\" season_label <- paste0(first_year + yr, \"/\", first_year + yr + 1)  res_i <- readRDS(paste0(\"results/augmented_multiple_seasons\", model, \".rds\"))[[yr]] x_samples <- res_i$x_samples lambda_samples <- res_i$lambda_samples  Y_ij <- ATP_2000_2022[[yr]]$Y_ij N_ij <- ATP_2000_2022[[yr]]$N_ij pl_df <- ATP_2000_2022[[yr]]$players_df"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"relabel-draws-by-lambda-rank","dir":"Articles","previous_headings":"Overview > Focused analysis for a single season","what":"Relabel draws by λ\\lambda rank","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"relabel_by_lambda <- function(x_draws, lambda_draws) {   K <- ncol(lambda_draws)   out_x <- x_draws   out_lambda <- lambda_draws   for (i in seq_len(nrow(lambda_draws))) {     ord <- order(lambda_draws[i, ], decreasing = TRUE)     out_lambda[i, ] <- lambda_draws[i, ord]     renamer <- match(seq_len(K), ord)     out_x[i, ] <- renamer[x_draws[i, ]]   }   list(x = out_x, lambda = out_lambda) }  k_target <- 5 keep <- apply(x_samples, 1, \\(z) length(unique(z)) == k_target) x_k5 <- x_samples[keep, , drop = FALSE] lambda_k5 <- lambda_samples[keep, , drop = FALSE] relab <- relabel_by_lambda(x_k5, lambda_k5) x_k5 <- relab$x lambda_k5 <- relab$lambda"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"lambda-uncertainty-plot","dir":"Articles","previous_headings":"Overview > Focused analysis for a single season","what":"λ\\lambda uncertainty plot","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"idx_mat <- cbind(rep(seq_len(nrow(x_k5)), each = ncol(x_k5)),                  as.vector(x_k5)) lambda_player <- matrix(lambda_k5[idx_mat],                         nrow = nrow(x_k5),                         ncol = ncol(x_k5),                         byrow = FALSE) colnames(lambda_player) <- colnames(x_k5)  log_lp <- log10(lambda_player) hpd90 <- t(apply(log_lp, 2, \\(v) HPDinterval(as.mcmc(v), prob = 0.90)))  player_summ <- data.frame(   player  = colnames(Y_ij),   mean    = 10^(colMeans(log_lp)),   low90   = 10^(hpd90[, 1]),   up90    = 10^(hpd90[, 2]),   cluster = inference_helper(x_samples, lambda_samples)$partition_expected ) |>   arrange(cluster, desc(mean)) |>   mutate(player = sapply(str_to_title(gsub(\"_\", \" \", player)), clean_players_names),          player = factor(player, levels = rev(player)))  ggplot(player_summ, aes(x = mean, y = player, colour = factor(cluster))) +   geom_pointrange(aes(xmin = low90, xmax = up90), size = 0.4, fatten = 0.6) +   scale_x_log10() +   labs(x = expression(lambda~\"(posterior mean, log\"[10]*\" scale)\"), y = NULL, color = \"Cluster\") +   theme_minimal() +   theme(axis.text.y = element_text(size = 6), panel.grid.minor = element_blank())"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"block-ordered-adjacency-heatmap","dir":"Articles","previous_headings":"Overview > Focused analysis for a single season","what":"Block-ordered adjacency heatmap","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"inf_i <- inference_helper(res_i$x_samples, lambda_samples = res_i$lambda_samples) x_relabel <- inf_i$x_samples_relabel lambdas_reordered <- inf_i$lambda_samples_relabel partition_minVI <- inference_helper(x_relabel, lambdas_reordered)$partition_expected  df_cl <- data.frame(   players = rownames(Y_ij),   cl = partition_minVI,   marginal_win = rowSums(Y_ij) )  Y_long <- melt(Y_ij) colnames(Y_long) <- c(\"Winner\", \"Loser\", \"Win_Count\") Y_long$Matches_Count <- melt(N_ij)$value  Y_long_plot <- Y_long %>%   mutate(perc_success = Win_Count / Matches_Count) %>%   left_join(df_cl, by = c(\"Loser\" = \"players\")) %>% rename(row_cl = cl, marginal_win_row = marginal_win) %>%   left_join(df_cl, by = c(\"Winner\" = \"players\")) %>% rename(col_cl = cl, marginal_win_col = marginal_win) %>%   mutate(     Winner = sapply(str_to_title(gsub(\"_\", \" \", Winner)), clean_players_names),     Loser  = sapply(str_to_title(gsub(\"_\", \" \", Loser)),  clean_players_names)   ) %>%   mutate(     Winner = factor(Winner, levels = unique(Winner[order(col_cl, -marginal_win_col, decreasing = TRUE)])),     Loser  = factor(Loser,  levels = unique(Loser[order(row_cl, -marginal_win_row)])),     col_cl = factor(col_cl, ordered = TRUE)   )  # boundaries v_lines_list <- Y_long_plot %>% group_by(row_cl) %>% summarize(x_break = max(as.numeric(Loser)), .groups = \"drop\") %>% pull(x_break) v_lines_list <- v_lines_list[-length(v_lines_list)] h_lines_list <- Y_long_plot %>% group_by(col_cl) %>% summarize(y_break = min(as.numeric(Winner)), .groups = \"drop\") %>% pull(y_break) h_lines_list <- h_lines_list[-length(h_lines_list)]  ggplot(Y_long_plot, aes(x = Loser, y = Winner)) +   geom_tile(aes(fill = perc_success), color = 'grey40') +   scale_fill_gradient(low = \"#FFFFCC\", high = \"#006400\", na.value = \"#009680\") +   geom_ysidecol(aes(color = factor(col_cl))) +   geom_vline(xintercept = unlist(v_lines_list) + 0.5, color = 'black', linewidth = 0.3) +   geom_hline(yintercept = unlist(h_lines_list) - 0.5, color = 'black', linewidth = 0.3) +   labs(x = \"Players (ordered by block)\", y = \"Players (ordered by block)\", fill = \"% victories\", color = \"Block\") +   theme_minimal(base_size = 12) +   theme(axis.text.x = element_blank(), panel.grid = element_blank(), legend.position = \"left\") +   theme_ggside_void() +   scale_y_discrete(guide = guide_axis(n.dodge = 2)) +   coord_fixed(ratio = 1)"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"assignment-probability-heatmap","dir":"Articles","previous_headings":"Overview > Focused analysis for a single season","what":"Assignment probability heatmap","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"count_cl <- function(x) length(unique(x)) unique_count <- apply(x_samples, 1, count_cl) x_samples_sub <- x_samples[unique_count == 5, , drop = FALSE] lambda_samples_sub <- lambda_samples[unique_count == 5, , drop = FALSE] inf_i <- inference_helper(x_samples_sub, lambda_samples_sub)  block_prob <- inf_i$player_block_assignment_probs[, 1:5] block_prob <- cbind(block_prob, pl_name = rownames(Y_ij))  assignment_probs_long <- block_prob %>%   pivot_longer(cols = 1:5, names_to = \"Cluster\", values_to = \"prob\") %>%   mutate(Cluster = gsub(\"_\", \" \", Cluster),          pl_name = gsub(\"_\", \" \", pl_name))  max_prob_clusters <- assignment_probs_long %>%   group_by(pl_name) %>%   summarize(Cl_ass = Cluster[which.max(prob)], .groups = \"drop\")  marg_pro_win <- data.frame(   pl_name = rownames(Y_ij),   marg_pro_win  = rowSums(Y_ij),   marg_pro_loss = colSums(Y_ij) ) %>%   mutate(pct_win = marg_pro_win / (marg_pro_loss + marg_pro_win),          pl_name = gsub(\"_\", \" \", pl_name))  assignment_probs_long_plot <- assignment_probs_long %>%   left_join(max_prob_clusters, by = \"pl_name\") %>%   left_join(marg_pro_win, by = \"pl_name\") %>%   mutate(pl_name = sapply(str_to_title(pl_name), clean_players_names),          pl_name = factor(pl_name, levels = unique(pl_name[order(Cl_ass, -marg_pro_win, decreasing = TRUE)]),                           ordered = TRUE))  ggplot(assignment_probs_long_plot) +   geom_tile(aes(x = Cluster, y = pl_name, fill = prob)) +   scale_fill_gradient(low = \"#FFFFCC\", high = \"#006400\", na.value = \"#009680\") +   labs(x = \"\", y = \"\", fill = \"Assign. Prob.\") +   theme_minimal() +   theme(axis.text.x = element_text(angle = 90),         axis.title.x = element_blank(),         axis.title.y = element_blank()) +   scale_y_discrete(guide = guide_axis(n.dodge = 2))"},{"path":"https://laposanti.github.io/BTSBM/articles/Post_processing_BTSBM.html","id":"player-trajectories-example","dir":"Articles","previous_headings":"Overview > Focused analysis for a single season","what":"Player trajectories (example)","title":"Post-processing and Summary Plots for BT-SBM","text":"","code":"pl_selected <- c(\"Rafael Nadal\", \"Roger Federer\", \"Novak Djokovic\", \"Andy Murray\")  prob_assignment_across_years %>%   filter(pl_name %in% pl_selected) %>%   ggplot(aes(x = season, y = Cluster_1 * 100, group = pl_name, color = pl_name)) +   geom_line() +   theme_minimal() +   labs(y = \"P(Top Block) (%)\", x = \"Season\", color = \"Player\") +   theme(axis.text.x = element_text(angle = 90)) +   facet_wrap(~pl_name)"},{"path":"https://laposanti.github.io/BTSBM/articles/getting-started.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Getting Started: Single-K Simulation Walkthrough","text":"vignette replicates spirit larger simulation pipeline, focuses single value K single dataset keep things simple fast -simulate sparse paired-comparison topology, -simulate latent blocks block rates, -generate win counts wijw_{ij} -run clustered Gibbs sampler (gibbs_bt_sbm), -relabel summarize (inference_helper), -compare inferred partition truth via VI distance.","code":""},{"path":"https://laposanti.github.io/BTSBM/articles/getting-started.html","id":"load-packages","dir":"Articles","previous_headings":"Overview","what":"Load packages","title":"Getting Started: Single-K Simulation Walkthrough","text":"Helpers Simulate one dataset (single K) Run clustered Gibbs sampler (short chain) Relabel summarize Posterior similarity matrix (PSM):  Per-player assignment probabilities (first rows): Compare partitions truth (VI distance) compute VI distances minVI Binder partitions true labels z_star. Tip: also want ARI, use mclust::adjustedRandIndex(post$minVI_partition, z_star) script article (’s heavier; keep vignette light). Optional: Build LOO matrices model comparison just show calls; evaluate scripts needed.","code":"library(BTSBM)        # this package library(mcclust)      # comp.psm, vi.dist #> Loading required package: lpSolve library(mcclust.ext)  # minVI, minbinder.ext # Random sparse match topology via Poisson counts on each unordered pair sample_Nij <- function(n_players, lambda = 3) {   pairs <- utils::combn(n_players, 2)   N_out <- matrix(0L, n_players, n_players)   for (k in seq_len(ncol(pairs))) {     i <- pairs[1, k]; j <- pairs[2, k]     n_ij <- rpois(1, lambda)     N_out[i, j] <- N_out[j, i] <- n_ij   }   diag(N_out) <- 0L   N_out }  # Map block rates to pairwise BT probabilities lambda_to_theta <- function(lambda) {   outer(lambda, lambda, function(a, b) a / (a + b)) } K <- 5                  # single K for this vignette n <- 60                 # number of players/items  # --- match topology (symmetric, diag 0) N_ij <- sample_Nij(n_players = n, lambda = 2)  # --- latent block structure and rates z_star <- sample.int(K, n, replace = TRUE)               # true labels lambda_star <- seq(0.8, 2.0, length.out = K)             # monotone blocks theta_star  <- lambda_to_theta(lambda_star)              # K x K BT probs  # --- generate wins w_ij <- matrix(0L, n, n) idx  <- which(upper.tri(N_ij) & N_ij > 0L, arr.ind = TRUE) for (k in seq_len(nrow(idx))) {   i <- idx[k, 1]; j <- idx[k, 2]   nij <- N_ij[i, j]   pij <- theta_star[z_star[i], z_star[j]]   wij <- rbinom(1, size = nij, prob = pij)   w_ij[i, j] <- wij   w_ij[j, i] <- nij - wij } out <- gibbs_bt_sbm(   w_ij   = w_ij,   n_ij   = N_ij,   a      = 1, b = 1,   prior  = \"DP\",       # \"DP\", \"PY\", \"DM\", or \"GN\"   alpha_PY = 1,   n_iter = 800, burnin = 300,   verbose = FALSE )  str(out, max.level = 1) #> List of 3 #>  $ x_samples     : int [1:500, 1:60] 7 7 7 7 7 7 7 7 7 7 ... #>  $ lambda_samples: num [1:500, 1:60] 2.01 1.97 1.78 2.21 2.22 ... #>  $ z_samples     : NULL post <- inference_helper(out$x_samples, out$lambda_samples)  # Average number of clusters, and distribution over #clusters post$avg_n_clusters #> [1] 3.858 table(post$n_clusters_each_iter) #>  #>   2   3   4   5   6   7   8  #>  80 141 138  81  39  13   8 image(post$co_clustering, main = \"Posterior Similarity Matrix\", axes = FALSE) head(post$player_block_assignment_probs) #>          Cluster_1 Cluster_2 Cluster_3 Cluster_4 Cluster_5 Cluster_6 Cluster_7 #> Player_1     0.630     0.284     0.056     0.022     0.006     0.002     0.000 #> Player_2     0.804     0.176     0.018     0.002     0.000     0.000     0.000 #> Player_3     0.822     0.160     0.016     0.002     0.000     0.000     0.000 #> Player_4     0.754     0.214     0.030     0.002     0.000     0.000     0.000 #> Player_5     0.216     0.338     0.236     0.140     0.050     0.012     0.006 #> Player_6     0.028     0.338     0.306     0.210     0.082     0.024     0.006 #>          Cluster_8 Cluster_9 Cluster_10 Cluster_11 Cluster_12 Cluster_13 #> Player_1     0.000         0          0          0          0          0 #> Player_2     0.000         0          0          0          0          0 #> Player_3     0.000         0          0          0          0          0 #> Player_4     0.000         0          0          0          0          0 #> Player_5     0.002         0          0          0          0          0 #> Player_6     0.006         0          0          0          0          0 #>          Cluster_14 Cluster_15 Cluster_16 Cluster_17 Cluster_18 Cluster_19 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_20 Cluster_21 Cluster_22 Cluster_23 Cluster_24 Cluster_25 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_26 Cluster_27 Cluster_28 Cluster_29 Cluster_30 Cluster_31 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_32 Cluster_33 Cluster_34 Cluster_35 Cluster_36 Cluster_37 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_38 Cluster_39 Cluster_40 Cluster_41 Cluster_42 Cluster_43 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_44 Cluster_45 Cluster_46 Cluster_47 Cluster_48 Cluster_49 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_50 Cluster_51 Cluster_52 Cluster_53 Cluster_54 Cluster_55 #> Player_1          0          0          0          0          0          0 #> Player_2          0          0          0          0          0          0 #> Player_3          0          0          0          0          0          0 #> Player_4          0          0          0          0          0          0 #> Player_5          0          0          0          0          0          0 #> Player_6          0          0          0          0          0          0 #>          Cluster_56 Cluster_57 Cluster_58 Cluster_59 Cluster_60 #> Player_1          0          0          0          0          0 #> Player_2          0          0          0          0          0 #> Player_3          0          0          0          0          0 #> Player_4          0          0          0          0          0 #> Player_5          0          0          0          0          0 #> Player_6          0          0          0          0          0 vi_minvi  <- mcclust::vi.dist(post$minVI_partition,   z_star) vi_binder <- mcclust::vi.dist(post$partition_binder,  z_star)  c(VI_minVI = vi_minvi, VI_binder = vi_binder) #>  VI_minVI VI_binder  #>  2.147630  2.168204 # Simple BT (player-level) log-likelihood matrix simple_llo <- make_bt_simple_loo(   w_ij = w_ij, n_ij = N_ij,   lambda_samples = out$lambda_samples )  # Clustered BT–SBM log-likelihood matrix cluster_llo <- make_bt_cluster_loo(   w_ij = w_ij, n_ij = N_ij,   lambda_samples = post$lambda_samples_relabel,   x_samples      = post$x_samples_relabel )"},{"path":"https://laposanti.github.io/BTSBM/articles/getting-started.html","id":"compare-via-psis-loo-requires-loo","dir":"Articles","previous_headings":"Overview","what":"Compare via PSIS-LOO (requires ‘loo’)","title":"Getting Started: Single-K Simulation Walkthrough","text":"","code":"cmp <- compare_bt_models_loo(simple_llo, cluster_llo) #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Can't fit generalized Pareto distribution because all tail values are #> the same. #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. #> Warning: Some Pareto k diagnostic values are too high. See help('pareto-k-diagnostic') for details. #> Warning in loo::compare(loo_simple, loo_cluster): 'loo::compare' is deprecated. #> Use 'loo_compare' instead. #> See help(\"Deprecated\") cmp$comparison #> elpd_diff        se  #>     772.8      64.1"},{"path":"https://laposanti.github.io/BTSBM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Lapo Santi. Author, maintainer.","code":""},{"path":"https://laposanti.github.io/BTSBM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Santi L (2025). BTSBM: Bayesian Bradley–Terry Stochastic Block Models Paired Comparison Data. R package version 0.1.0, https://github.com/laposanti/BTSBM.","code":"@Manual{,   title = {BTSBM: Bayesian Bradley–Terry Stochastic Block Models for Paired Comparison Data},   author = {Lapo Santi},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/laposanti/BTSBM}, }"},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":null,"dir":"Reference","previous_headings":"","what":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"yearly panel head--head counts top 105 ATP players, suitable Bradley–Terry/Stochastic Block Model analyses. season, data include () number wins player \\(\\) player \\(j\\) (ii) number matches played \\(\\) \\(j\\), along per-season player metadata tibble.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"","code":"ATP_2000_2022"},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"named list length 23, elements \"2000\", \"2001\", …, \"2022\". yearly element list length 3: Y_ij numeric matrix \\(105 \\times 105\\). Entry Y_ij[, j] count matches player \\(\\) defeated player \\(j\\) calendar year (nonnegative integer; diagonal zero). N_ij numeric matrix \\(105 \\times 105\\). Entry N_ij[, j] total number matches players \\(\\) \\(j\\) year (nonnegative integer; symmetric construction; diagonal zero). players_df tibble/data frame 105 rows 7 columns describing player index used matrices year: player Integer player identifier (row/column index used Y_ij N_ij). worst_rank Worst (numerically largest) ATP ranking attained player year. median_rank Median ATP ranking across player's ranking snapshots year. last_rank ATP ranking last snapshot available year (e.g., year-end ranking). age_year Approximate age (years) season (e.g., mid-season). ht_year Player height centimeters (season-level value). player_slug Character identifier (URL-safe underscored name) player.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"Aggregated package author public ATP results (e.g., tennis\\_atp datasets Jeff Sackmann) internal preprocessing. See package vignette provenance cleaning steps.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"player ordering players_df defines row/column indexing Y_ij N_ij corresponding year. diagonal entries matrices zero definition. typical usage Bradley–Terry-type models, one can treat Y_ij[, j] number “successes” \\(\\) vs. \\(j\\), binomial denominator N_ij[, j].","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"matrices may sparse many player pairs. Ensure model code guards divisions zero N_ij[, j] = 0.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/ATP_2000_2022.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"ATP Paired-Comparison Panels, 2000–2022 — ATP_2000_2022","text":"","code":"data(ATP_2000_2022) names(ATP_2000_2022) #>  [1] \"2000\" \"2001\" \"2002\" \"2003\" \"2004\" \"2005\" \"2006\" \"2007\" \"2008\" \"2009\" #> [11] \"2010\" \"2011\" \"2012\" \"2013\" \"2014\" \"2015\" \"2016\" \"2017\" \"2018\" \"2019\" #> [21] \"2020\" \"2021\" \"2022\" year <- \"2000\" str(ATP_2000_2022[[year]]) #> List of 3 #>  $ Y_ij      : num [1:105, 1:105] 0 0 1 1 1 1 0 0 0 1 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:105] \"Gustavo_Kuerten\" \"Marat_Safin\" \"Pete_Sampras\" \"Magnus_Norman\" ... #>   .. ..$ : chr [1:105] \"Gustavo_Kuerten\" \"Marat_Safin\" \"Pete_Sampras\" \"Magnus_Norman\" ... #>  $ N_ij      : num [1:105, 1:105] 0 2 2 4 3 3 1 1 0 1 ... #>   ..- attr(*, \"dimnames\")=List of 2 #>   .. ..$ : chr [1:105] \"Gustavo_Kuerten\" \"Marat_Safin\" \"Pete_Sampras\" \"Magnus_Norman\" ... #>   .. ..$ : chr [1:105] \"Gustavo_Kuerten\" \"Marat_Safin\" \"Pete_Sampras\" \"Magnus_Norman\" ... #>  $ players_df: tibble [105 × 7] (S3: tbl_df/tbl/data.frame) #>   ..$ player     : int [1:105] 102856 103498 101948 102796 102338 101736 103720 102374 102358 102450 ... #>   ..$ worst_rank : int [1:105] 7 38 4 14 8 8 21 32 12 17 ... #>   ..$ median_rank: num [1:105] 4 9 2 4 5 1 9 10 8 10 ... #>   ..$ last_rank  : int [1:105] 1 2 3 4 5 6 7 8 9 10 ... #>   ..$ age_year   : num [1:105] 23.7 20.4 28.8 23.9 26.4 ... #>   ..$ ht_year    : num [1:105] 190 193 185 188 190 180 180 180 190 185 ... #>   ..$ player_slug: chr [1:105] \"Gustavo_Kuerten\" \"Marat_Safin\" \"Pete_Sampras\" \"Magnus_Norman\" ...  # Player i's total wins that year: i <- 1 sum(ATP_2000_2022[[year]]$Y_ij[i, ], na.rm = TRUE) #> [1] 52  # Total matches between i and j: j <- 2 ATP_2000_2022[[year]]$N_ij[i, j] #> [1] 2  # Join player metadata to indices used in the matrices: head(ATP_2000_2022[[year]]$players_df) #> # A tibble: 6 × 7 #>   player worst_rank median_rank last_rank age_year ht_year player_slug        #>    <int>      <int>       <dbl>     <int>    <dbl>   <dbl> <chr>              #> 1 102856          7           4         1     23.7     190 Gustavo_Kuerten    #> 2 103498         38           9         2     20.4     193 Marat_Safin        #> 3 101948          4           2         3     28.8     185 Pete_Sampras       #> 4 102796         14           4         4     23.9     188 Magnus_Norman      #> 5 102338          8           5         5     26.4     190 Yevgeny_Kafelnikov #> 6 101736          8           1         6     30.1     180 Andre_Agassi"},{"path":"https://laposanti.github.io/BTSBM/reference/HGnedin.html","id":null,"dir":"Reference","previous_headings":"","what":"Gnedin prior normalization weight H(V,h) — HGnedin","title":"Gnedin prior normalization weight H(V,h) — HGnedin","text":"Computes unnormalized mass function term used Gnedin-type priors.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/HGnedin.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gnedin prior normalization weight H(V,h) — HGnedin","text":"","code":"HGnedin(V, h, gamma = 0.5)"},{"path":"https://laposanti.github.io/BTSBM/reference/HGnedin.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gnedin prior normalization weight H(V,h) — HGnedin","text":"V integer(1) total items. h integer vector block counts. gamma numeric(1) parameter \\(\\gamma > 0\\).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/HGnedin.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gnedin prior normalization weight H(V,h) — HGnedin","text":"Numeric vector weights \\(H(V,h)\\).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/clean_players_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Format player names as ","title":"Format player names as ","text":"Format player names \"Surname F.\"","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/clean_players_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Format player names as ","text":"","code":"clean_players_names(name)"},{"path":"https://laposanti.github.io/BTSBM/reference/clean_players_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Format player names as ","text":"name character scalar vector (e.g., \"Roger Federer\").","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/clean_players_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Format player names as ","text":"Character vector formatted names (e.g., \"Federer R.\").","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/clean_players_names.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Format player names as ","text":"","code":"clean_players_names(c(\"Roger Federer\", \"Nadal\")) #> [1] \"Federer R .\" \"Nadal\""},{"path":"https://laposanti.github.io/BTSBM/reference/compare_bt_models_loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare BT models with Pareto-smoothed importance sampling LOO — compare_bt_models_loo","title":"Compare BT models with Pareto-smoothed importance sampling LOO — compare_bt_models_loo","text":"Convenience wrapper around loo comparing two log-likelihood matrices (simple vs clustered BT).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/compare_bt_models_loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare BT models with Pareto-smoothed importance sampling LOO — compare_bt_models_loo","text":"","code":"compare_bt_models_loo(simple_llo, cluster_llo)  compare_bt_models_loo(simple_llo, cluster_llo)"},{"path":"https://laposanti.github.io/BTSBM/reference/compare_bt_models_loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare BT models with Pareto-smoothed importance sampling LOO — compare_bt_models_loo","text":"simple_llo list returned make_bt_simple_loo(). cluster_llo list returned make_bt_cluster_loo().","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/compare_bt_models_loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare BT models with Pareto-smoothed importance sampling LOO — compare_bt_models_loo","text":"list : simple — loo object simple BT. cluster — loo object clustered BT–SBM. comparison — result loo::compare_models(). list : simple — loo object simple BT. cluster — loo object clustered BT–SBM. comparison — result loo::compare().","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/expected_cl_py.html","id":null,"dir":"Reference","previous_headings":"","what":"Expected number of clusters under finite/inf PY/DM-like priors (helper) — expected_cl_py","title":"Expected number of clusters under finite/inf PY/DM-like priors (helper) — expected_cl_py","text":"Expected number clusters finite/inf PY/DM-like priors (helper)","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/expected_cl_py.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Expected number of clusters under finite/inf PY/DM-like priors (helper) — expected_cl_py","text":"","code":"expected_cl_py(n, sigma, theta, H)"},{"path":"https://laposanti.github.io/BTSBM/reference/expected_cl_py.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Expected number of clusters under finite/inf PY/DM-like priors (helper) — expected_cl_py","text":"n integer(1) number items. sigma numeric(1) discount (0 DP/DM). theta numeric(1) concentration parameter. H integer(1) maximum number clusters, Inf.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/expected_cl_py.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Expected number of clusters under finite/inf PY/DM-like priors (helper) — expected_cl_py","text":"Numeric(1) expected number clusters.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_sbm.html","id":null,"dir":"Reference","previous_headings":"","what":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","title":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","text":"Runs Gibbs sampler BT–SBM Gamma(, b) prior block rates choice clustering prior (DP, Pitman–Yor, Dirichlet–Multinomial, Gnedin).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_sbm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","text":"","code":"gibbs_bt_sbm(   w_ij,   n_ij,   a,   b,   prior = \"DP\",   alpha_PY = NA_real_,   sigma_PY = NA_real_,   beta_DM = NA_real_,   H_DM = NA_integer_,   gamma_GN = NA_real_,   n_iter = 2000L,   burnin = 1000L,   init_x = NULL,   store_z = FALSE,   verbose = TRUE,   a_prior_draw = function() rexp(1, 1),   a_prior_support = function(a) a > 0 )"},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_sbm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","text":"w_ij integer/numeric K x K matrix wins j (diagonal ignored). n_ij integer/numeric K x K matrix total matches j (symmetric, diag 0). numeric(1). Shape Gamma(, b) prior block rate init; updated inside. b numeric(1). Rate Gamma(, b) prior (fixed). prior character(1). One c(\"DP\",\"PY\",\"DM\",\"GN\"). alpha_PY numeric(1) NA. Concentration DP/PY (must > 0 used). sigma_PY numeric(1) NA. Discount PY [0,1); set 0 DP using \"PY\". beta_DM numeric(1) NA. Dirichlet-Multinomial concentration (>0) prior=\"DM\". H_DM integer(1) NA. Max # clusters DM (>=1) prior=\"DM\". gamma_GN numeric(1) NA. Parameter Gnedin prior=\"GN\". n_iter integer(1). Total MCMC iterations. burnin integer(1). Number initial iterations discard (must < n_iter). init_x integer vector length K initial cluster labels (1..K), NULL. store_z logical(1). TRUE, store latent Z matrices. verbose logical(1). TRUE, print progress every 200 iters. a_prior_draw function signature function() numeric(1). Draws proposal prior \\(\\) (Damien slice sampler). Default function() rexp(1, 1) (Exp(1) \\(>0\\)). a_prior_support function signature function() logical(1). Checks support \\(\\). Default: function() > 0.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_sbm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","text":"list : x_samples (n_save x K) integer matrix cluster labels burn-. lambda_samples (n_save x K) numeric matrix block rates (entries empty labels can unused). z_samples optional (n_save x K x K) array latent \\(Z_{ij}\\) store_z=TRUE.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_sbm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","text":"sampler uses Gamma-Poisson augmentation BT likelihood: \\(Z_{ij} \\sim \\mathrm{Gamma}(n_{ij}, \\lambda_{x_i}+\\lambda_{x_j})\\). Cluster reassignment uses one-step CRP/PY/DM/GN urn marginal new-cluster integral \\(\\lambda \\sim \\mathrm{Gamma}(,b)\\). \\(\\) updated via Damien-style slice move joint \\(\\lambda\\) given \\(b\\) prior \\(\\).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_sbm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gibbs sampler for a Bradley–Terry Stochastic Block Model — gibbs_bt_sbm","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) K <- 6 w <- matrix(0, K, K); n <- matrix(0, K, K) n[upper.tri(n)] <- sample(0:5, sum(upper.tri(n)), TRUE) n <- n + t(n); diag(n) <- 0 w[upper.tri(w)] <- rbinom(sum(upper.tri(w)), size = n[upper.tri(n)], prob = 0.5) w <- w + t(n - w); diag(w) <- 0 out <- gibbs_bt_sbm(w, n, a = 1, b = 1, prior = \"DP\", alpha_PY = 1,                     n_iter = 500, burnin = 250, verbose = FALSE) str(out) } # }"},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_simple.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple Bradley–Terry Gibbs sampler (no clustering) — gibbs_bt_simple","title":"Simple Bradley–Terry Gibbs sampler (no clustering) — gibbs_bt_simple","text":"Simple Bradley–Terry Gibbs sampler (clustering)","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_simple.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple Bradley–Terry Gibbs sampler (no clustering) — gibbs_bt_simple","text":"","code":"gibbs_bt_simple(   w_ij,   n_ij,   a = 0.01,   b = 1,   n_iter = 5000,   burnin = 1000,   verbose = TRUE )"},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_simple.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple Bradley–Terry Gibbs sampler (no clustering) — gibbs_bt_simple","text":"w_ij integer/numeric K x K wins j. n_ij integer/numeric K x K total matches (symmetric, diag = 0). , b numeric(1) Gamma(,b) prior \\(\\lambda_i\\). n_iter, burnin integers; total iterations burn-. verbose logical; print progress.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_simple.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simple Bradley–Terry Gibbs sampler (no clustering) — gibbs_bt_simple","text":"list lambda_samples (matrix size (n_iter-burnin) x K).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/gibbs_bt_simple.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simple Bradley–Terry Gibbs sampler (no clustering) — gibbs_bt_simple","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) K <- 6 n <- matrix(0, K, K); n[upper.tri(n)] <- sample(0:3, sum(upper.tri(n)), TRUE) n <- n + t(n); diag(n) <- 0 w <- matrix(0, K, K); w[upper.tri(w)] <- rbinom(sum(upper.tri(n)), n[upper.tri(n)], 0.5) w <- w + t(n - w); diag(w) <- 0 fit <- gibbs_bt_simple(w, n, a = 1, b = 1, n_iter = 500, burnin = 100, verbose = FALSE) } # }"},{"path":"https://laposanti.github.io/BTSBM/reference/inference_helper.html","id":null,"dir":"Reference","previous_headings":"","what":"Post-processing for BT–SBM posterior draws — inference_helper","title":"Post-processing for BT–SBM posterior draws — inference_helper","text":"Relabels MCMC draw descending block rate \\(\\lambda\\), computes posterior similarity matrix (PSM), point partitions (Binder minVI), summary stats number clusters, per-player assignment probabilities. Relabels MCMC draw descending block rate \\(\\lambda\\), computes posterior similarity matrix (PSM), Binder minVI point partitions, cluster count summaries, per-player assignment probabilities.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/inference_helper.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Post-processing for BT–SBM posterior draws — inference_helper","text":"","code":"inference_helper(x_samples, lambda_samples)  inference_helper(x_samples, lambda_samples)"},{"path":"https://laposanti.github.io/BTSBM/reference/inference_helper.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Post-processing for BT–SBM posterior draws — inference_helper","text":"x_samples integer matrix (M x K). Cluster labels per draw (row = one draw). lambda_samples numeric matrix (M x K). Block rates per draw (aligned labels).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/inference_helper.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Post-processing for BT–SBM posterior draws — inference_helper","text":"list components: x_samples_relabel, lambda_samples_relabel — relabeled draws. co_clustering — PSM (K x K). partition_binder, minVI_partition, partition_expected. n_clusters_each_iter, avg_n_clusters. player_block_assignment_probs (K x K data.frame). block_count_distribution (data.frame num_blocks, count, prob). top_block_count_per_iter, avg_top_block_count. list components: x_samples_relabel, lambda_samples_relabel — relabeled draws. co_clustering — PSM (K x K). partition_binder, minVI_partition, partition_expected. n_clusters_each_iter, avg_n_clusters. player_block_assignment_probs (K x K data.frame). block_count_distribution (data.frame num_blocks, count, prob). top_block_count_per_iter, avg_top_block_count.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/inference_helper.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Post-processing for BT–SBM posterior draws — inference_helper","text":"Relabeling done within draw sorting occupied blocks decreasing \\(\\lambda\\). Block 1 “top” block draw.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/inference_helper.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Post-processing for BT–SBM posterior draws — inference_helper","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) M <- 100; K <- 6 x  <- matrix(sample.int(3, M*K, TRUE), M, K) lam <- matrix(rexp(M*K), M, K) out <- inference_helper(x, lam) str(out) } # } if (FALSE) { # \\dontrun{ set.seed(1) M <- 100; K <- 6 x  <- matrix(sample.int(3, M*K, TRUE), M, K) lam <- matrix(rexp(M*K), M, K) out <- inference_helper(x, lam) str(out) } # }"},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_cluster_loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-likelihood matrix for the BT–SBM (clustered) model — make_bt_cluster_loo","title":"Log-likelihood matrix for the BT–SBM (clustered) model — make_bt_cluster_loo","text":"Builds S x D matrix log-likelihood values using cluster labels \\(x_i\\) cluster rates \\(\\lambda_k\\). Assumes x_samples lambda_samples relabelled consistently (e.g. via inference_helper). Builds S x D matrix log-likelihood values using cluster labels \\(x_i\\) cluster rates \\(\\lambda_k\\). Assumes inputs relabelled consistently.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_cluster_loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-likelihood matrix for the BT–SBM (clustered) model — make_bt_cluster_loo","text":"","code":"make_bt_cluster_loo(w_ij, n_ij, lambda_samples, x_samples)  make_bt_cluster_loo(w_ij, n_ij, lambda_samples, x_samples)"},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_cluster_loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-likelihood matrix for the BT–SBM (clustered) model — make_bt_cluster_loo","text":"w_ij integer/numeric K x K wins (j). n_ij integer/numeric K x K total matches (symmetric, diag=0). lambda_samples numeric S x K matrix cluster rates \\(\\lambda_k\\). x_samples integer S x K matrix cluster labels player.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_cluster_loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-likelihood matrix for the BT–SBM (clustered) model — make_bt_cluster_loo","text":"list : ll — S x D matrix log-likelihoods. obs_idx — D x 2 matrix (,j) indices defining column. list : ll — S x D matrix log-likelihoods. obs_idx — D x 2 matrix (,j) indices defining column.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_cluster_loo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-likelihood matrix for the BT–SBM (clustered) model — make_bt_cluster_loo","text":"","code":"if (FALSE) { # \\dontrun{ # After running your clustered sampler and relabeling: # ll_obj <- make_bt_cluster_loo(w, n, out$lambda_samples_relabel, out$x_samples_relabel) } # }"},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_loo_cluster.html","id":null,"dir":"Reference","previous_headings":"","what":"Build BT clustered log-likelihood matrix (player-level) — make_bt_loo_cluster","title":"Build BT clustered log-likelihood matrix (player-level) — make_bt_loo_cluster","text":"Convenience alternative returning plain S x P matrix (P = #pairs).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_loo_cluster.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build BT clustered log-likelihood matrix (player-level) — make_bt_loo_cluster","text":"","code":"make_bt_loo_cluster(x_draws, lambda_draws, w_ij, n_ij)"},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_loo_cluster.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build BT clustered log-likelihood matrix (player-level) — make_bt_loo_cluster","text":"x_draws integer S x K matrix cluster labels per draw. lambda_draws numeric S x K matrix cluster rates per draw. w_ij, n_ij K x K wins matches.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_loo_cluster.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build BT clustered log-likelihood matrix (player-level) — make_bt_loo_cluster","text":"Numeric matrix S x P log-likelihoods.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_simple_loo.html","id":null,"dir":"Reference","previous_headings":"","what":"Log-likelihood matrix for the simple Bradley–Terry model — make_bt_simple_loo","title":"Log-likelihood matrix for the simple Bradley–Terry model — make_bt_simple_loo","text":"Builds S x D matrix log-likelihood values, S number posterior draws D number observed unordered pairs (<j) n_ij > 0. suitable input loo. Builds S x D matrix log-likelihood values, S number posterior draws D number observed unordered pairs (<j) n_ij > 0.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_simple_loo.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Log-likelihood matrix for the simple Bradley–Terry model — make_bt_simple_loo","text":"","code":"make_bt_simple_loo(w_ij, n_ij, lambda_samples)  make_bt_simple_loo(w_ij, n_ij, lambda_samples)"},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_simple_loo.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Log-likelihood matrix for the simple Bradley–Terry model — make_bt_simple_loo","text":"w_ij integer/numeric K x K wins (j). n_ij integer/numeric K x K total matches (symmetric, diag=0). lambda_samples numeric S x K matrix player-specific rates \\(\\lambda_i\\).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_simple_loo.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Log-likelihood matrix for the simple Bradley–Terry model — make_bt_simple_loo","text":"list : ll — S x D matrix log-likelihoods. obs_idx — D x 2 matrix (,j) indices defining column. list : ll — S x D matrix log-likelihoods. obs_idx — D x 2 matrix (,j) indices defining column.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/make_bt_simple_loo.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Log-likelihood matrix for the simple Bradley–Terry model — make_bt_simple_loo","text":"","code":"if (FALSE) { # \\dontrun{ set.seed(1) K <- 5 n <- matrix(0, K, K); n[upper.tri(n)] <- sample(0:4, sum(upper.tri(n)), TRUE) n <- n + t(n); diag(n) <- 0 w <- matrix(0, K, K); w[upper.tri(w)] <- rbinom(sum(upper.tri(w)), n[upper.tri(n)], 0.5) w <- w + t(n - w); diag(w) <- 0 lam <- matrix(rexp(200*K), 200, K) ll_obj <- make_bt_simple_loo(w, n, lam) } # }"},{"path":"https://laposanti.github.io/BTSBM/reference/shannon_entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Shannon entropy of a discrete distribution — shannon_entropy","title":"Shannon entropy of a discrete distribution — shannon_entropy","text":"Shannon entropy discrete distribution Shannon entropy (nats)","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/shannon_entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Shannon entropy of a discrete distribution — shannon_entropy","text":"","code":"shannon_entropy(p)  shannon_entropy(p)"},{"path":"https://laposanti.github.io/BTSBM/reference/shannon_entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Shannon entropy of a discrete distribution — shannon_entropy","text":"p numeric vector nonnegative masses.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/shannon_entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Shannon entropy of a discrete distribution — shannon_entropy","text":"numeric(1) entropy nats. numeric(1) entropy nats.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DM.html","id":null,"dir":"Reference","previous_headings":"","what":"Urn weight: Dirichlet–Multinomial with max H_DM clusters — urn_DM","title":"Urn weight: Dirichlet–Multinomial with max H_DM clusters — urn_DM","text":"Urn weight: Dirichlet–Multinomial max H_DM clusters","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DM.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Urn weight: Dirichlet–Multinomial with max H_DM clusters — urn_DM","text":"","code":"urn_DM(v_minus, beta_DM, H_DM)"},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DM.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Urn weight: Dirichlet–Multinomial with max H_DM clusters — urn_DM","text":"v_minus integer sizes occupied clusters (excluding current item). beta_DM numeric concentration. H_DM integer maximum number clusters.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DM.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Urn weight: Dirichlet–Multinomial with max H_DM clusters — urn_DM","text":"Numeric vector length \\(H+1\\): existing weights new-cluster mass.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DP.html","id":null,"dir":"Reference","previous_headings":"","what":"Urn weight: Dirichlet Process — urn_DP","title":"Urn weight: Dirichlet Process — urn_DP","text":"Urn weight: Dirichlet Process","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Urn weight: Dirichlet Process — urn_DP","text":"","code":"urn_DP(v_minus, alpha_PY)"},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Urn weight: Dirichlet Process — urn_DP","text":"v_minus integer sizes occupied clusters (excluding current item). alpha_PY numeric concentration.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_DP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Urn weight: Dirichlet Process — urn_DP","text":"Numeric vector length \\(H+1\\): existing weights new-cluster mass.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_GN.html","id":null,"dir":"Reference","previous_headings":"","what":"Urn weight: Gnedin heuristic — urn_GN","title":"Urn weight: Gnedin heuristic — urn_GN","text":"Urn weight: Gnedin heuristic","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_GN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Urn weight: Gnedin heuristic — urn_GN","text":"","code":"urn_GN(v_minus, gamma)"},{"path":"https://laposanti.github.io/BTSBM/reference/urn_GN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Urn weight: Gnedin heuristic — urn_GN","text":"v_minus integer sizes occupied clusters (excluding current item). gamma numeric parameter.","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_GN.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Urn weight: Gnedin heuristic — urn_GN","text":"Numeric vector length \\(H+1\\).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_PY.html","id":null,"dir":"Reference","previous_headings":"","what":"Urn weight: Pitman–Yor process — urn_PY","title":"Urn weight: Pitman–Yor process — urn_PY","text":"Urn weight: Pitman–Yor process","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_PY.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Urn weight: Pitman–Yor process — urn_PY","text":"","code":"urn_PY(v_minus, alpha_PY, sigma_PY)"},{"path":"https://laposanti.github.io/BTSBM/reference/urn_PY.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Urn weight: Pitman–Yor process — urn_PY","text":"v_minus integer sizes occupied clusters (excluding current item). alpha_PY numeric concentration. sigma_PY numeric discount [0,1).","code":""},{"path":"https://laposanti.github.io/BTSBM/reference/urn_PY.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Urn weight: Pitman–Yor process — urn_PY","text":"Numeric vector length \\(H+1\\).","code":""}]
